# app/worker.py

import asyncio
import logging
import traceback
from datetime import datetime
from celery import Celery, signals
from celery.schedules import crontab
from celery.utils.log import get_task_logger

from app.core.config import settings
from app.db.session import SessionLocal 
from app.models.dashboard import BlogPost 
from app.models.quest import QuestTitle 
from app.models.user import User
from app.models.gift import DailyGift
from app.core.security import decrypt_token

# ì„œë¹„ìŠ¤ ì„í¬íŠ¸
from app.services.blog.github_blog_service import BlogDeployService
from app.services.github.github_client import GithubClient
from app.services.github.github_context_builder import GithubContextBuilder
from app.services.ai.ai_docs_site_generator import AiDocsBlogGenerator
from app.services.blog.blog_post_builder import BlogPostBuilder
from app.schemas.blog import FinalPostRequest
from app.services import quest_service 
from app.services.ai.ai_posting_service import AiPostingService 
from app.services.ai.docs_generator import DocsGeneratorService
from app.services.ai.gift_generator import GiftGeneratorService
from app.services.gift_service_logic import run_gift_generation_sync
from github import Github, GithubException

# ì›Œì»¤ ë¡œê±°
logger = get_task_logger(__name__)

celery_app = Celery(
    "eggit_worker",
    broker=settings.CELERY_BROKER_URL,
    backend=settings.CELERY_RESULT_BACKEND
)

celery_app.conf.update(
    task_serializer="json",
    result_serializer="json",
    accept_content=["json"],
    result_expires=3600, 
    timezone='Asia/Seoul', 
    enable_utc=False, 
)


# =================================================================
# 1. ê¸°ìˆ  ë¸”ë¡œê·¸ ë°°í¬ ì›Œì»¤ (Chirpy)
# =================================================================
@celery_app.task(bind=True)
def task_deploy_chirpy(self, token: str, repo_name: str, user_info: dict):
    try:
        service = BlogDeployService(user_token=token)
        service.deploy_chirpy_blog(repo_name, user_info)
        return {"status": "success", "repo": repo_name, "type": "chirpy"}
    except Exception as e:
        logger.error(f"âŒ Chirpy Deploy Task Failed: {e}")
        raise self.retry(exc=e, countdown=10, max_retries=3)


# =================================================================
# 2. ë¬¸ì„œ ì‚¬ì´íŠ¸ ë°°í¬ ì›Œì»¤ (Docs - AI Integration)
# =================================================================
@celery_app.task(bind=True)
def task_deploy_docs(self, token: str, target_repo: str, project_info: dict):
    logger.info(f"ğŸš€ Starting Docs Deployment for: {target_repo}")

    async def generate_ai_content():
        builder = GithubContextBuilder(token, target_repo)
        context = await (
            builder
            .with_tree()
            .with_readme()
            .with_tech_stack()
            .build()
        )
        
        if not context:
            logger.warning("âš ï¸ Failed to fetch repo context. Deploying empty docs.")
            return None

        context["repo_name"] = target_repo

        logger.info("ğŸ§  Generating documentation structure with AI...")
        ai_service = AiDocsBlogGenerator()
        structure_data = await ai_service.generate_structure(context)
        
        return structure_data

    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
        docs_structure = None
        try:
            docs_structure = loop.run_until_complete(generate_ai_content())
            if docs_structure and "root_structure" in docs_structure:
                logger.info(f"âœ… AI Generated {len(docs_structure['root_structure'])} categories.")
            else:
                logger.warning("âš ï¸ AI structure generation returned empty.")
        except Exception as ai_error:
            logger.error(f"âŒ AI Generation skipped due to error: {ai_error}")

        service = BlogDeployService(user_token=token)
        service.deploy_docs_site(target_repo, project_info, docs_structure=docs_structure)
        
        return {
            "status": "success", 
            "repo": target_repo, 
            "type": "docs",
            "ai_generated": bool(docs_structure)
        }

    except Exception as e:
        logger.error(f"âŒ Docs Deploy Task Failed: {e}")
        raise self.retry(exc=e, countdown=10, max_retries=3)


# =================================================================
# 5. í¬ìŠ¤íŒ… ì—…ë¡œë“œ ì›Œì»¤
# =================================================================
@celery_app.task(bind=True)
def task_post_to_blog(self, token: str, post_data_dict: dict, user_id: int):
    try:
        req = FinalPostRequest(**post_data_dict)
        g = Github(token)
        target_repo_name = req.blog_repo.strip()
        if "/" not in target_repo_name:
            auth_user = g.get_user() 
            target_repo_name = f"{auth_user.login}/{target_repo_name}"
        
        repo = g.get_repo(target_repo_name)
        target_branch = req.branch
        
        try:
            repo.get_branch(target_branch)
        except Exception:
            if req.theme_type == "docs":
                try:
                    repo.get_branch("gh-pages")
                    target_branch = "gh-pages"
                except:
                    target_branch = repo.default_branch
            else:
                target_branch = repo.default_branch
            logger.info(f"ğŸ”§ Branch Adjusted: '{req.branch}' -> '{target_branch}'")

        builder = BlogPostBuilder(req)
        if req.mode == 'update' and req.file_path:
            target_path = req.file_path
            _, content = builder.build()
        else:
            target_path, content = builder.build()

        commit_msg = f"[{req.mode.upper()}] {req.title} (via Eggit)"

        try:
            contents = repo.get_contents(target_path, ref=target_branch)
            logger.info(f"ğŸ“‚ File exists at {target_path}. Overwriting...")
            repo.update_file(target_path, commit_msg, content, contents.sha, branch=target_branch)
        except GithubException as e:
            if e.status == 404:
                logger.info(f"âœ¨ File not found at {target_path}. Creating new...")
                repo.create_file(target_path, commit_msg, content, branch=target_branch)
            else:
                raise e

        db = SessionLocal()
        try:
            username = target_repo_name.split("/")[0]
            if req.theme_type == "chirpy":
                slug = target_path.split("/")[-1].replace(".md", "")
                if "-" in slug and len(slug) > 11: slug = slug[11:] 
                post_url = f"https://{username}.github.io/posts/{slug}/"
            else:
                # [Fix] Docs URL ìƒì„± ë¡œì§ ìˆ˜ì • (html ì œê±°, Trailing Slash ì¶”ê°€)
                repo_only_name = target_repo_name.split("/")[-1]
                
                # 1. íŒŒì¼ ê²½ë¡œì—ì„œ í™•ì¥ì ì œê±°
                clean_path = target_path.replace(".md", "")
                
                # 2. index íŒŒì¼ì¸ ê²½ìš° ê²½ë¡œì—ì„œ ìƒëµ (Folder Root)
                if clean_path.endswith("index"):
                    clean_path = clean_path[:-5]
                
                # 3. Trailing Slash ë³´ì¥ (ê²½ë¡œê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°)
                if clean_path and not clean_path.endswith("/"):
                    clean_path += "/"
                
                post_url = f"https://{username}.github.io/{repo_only_name}/{clean_path}"

            new_activity = BlogPost(
                user_id=user_id,
                title=req.title,
                category=req.category,
                repository_name=target_repo_name,
                theme_type=req.theme_type,
                post_url=post_url
            )
            db.add(new_activity)
            target_quest = QuestTitle.TECH_BLOG_CUSTOM if req.theme_type == "chirpy" else QuestTitle.PROJECT_DOC
            quest_service.complete_quest_by_title(db, user_id=user_id, quest_title=target_quest)
            db.commit()

        except Exception as db_err:
            logger.error(f"âš ï¸ DB Post-Process Failed: {db_err}")
            db.rollback()
        finally:
            db.close()

        return {"status": "success", "path": target_path, "url": post_url}

    except Exception as e:
        logger.error(f"âŒ Post Task Failed: {e}")
        if hasattr(e, 'data'):
            logger.error(f"Github API Error Data: {e.data}")
        raise self.retry(exc=e, max_retries=3, countdown=5)


# =================================================================
# 5. ì£¼ê°„ í€˜ìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì›Œì»¤ (Cleanup)
# =================================================================
@celery_app.task
def task_cleanup_old_quest_records():
    """
    ë§¤ì£¼ ì›”ìš”ì¼ 00:00ì— ì‹¤í–‰
    - ë°ì¼ë¦¬/ìœ„í´ë¦¬ í€˜ìŠ¤íŠ¸ ì™„ë£Œ ê¸°ë¡ ì¤‘ 30ì¼(1ê°œì›”)ì´ ì§€ë‚œ ê¸°ë¡ì„ ì‚­ì œí•˜ì—¬ DB ìµœì í™”
    - 'ONE_TIME' ë°©ì‹ì´ ì•„ë‹Œ ê²ƒë“¤ë§Œ ì„ ë³„ì‚­ì œí•˜ë©°, ë°ì´í„° ì´ë ¥ì„ ë³´ì¡´í•˜ê¸° ìœ„í•´ ìµœê·¼ 1ê°œì›” ë°ì´í„°ëŠ” ë‚¨ê²¨ë‘ 
    """
    from app.db.session import SessionLocal
    from app.models.quest import Quest, UserQuest, QuestFrequency
    from datetime import datetime, timezone, timedelta
    
    db = SessionLocal()
    try:
        logger.info("ğŸ§¹ Starting weekly quest cleanup (preserving last 30 days)...")
        
        # 1. ë°ì¼ë¦¬/ìœ„í´ë¦¬ í€˜ìŠ¤íŠ¸ ID ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        repeatable_quest_ids = [
            q.id for q in db.query(Quest.id).filter(
                Quest.frequency.in_([QuestFrequency.DAILY, QuestFrequency.WEEKLY])
            ).all()
        ]
        
        if not repeatable_quest_ids:
            return "No repeatable quests to cleanup."

        # 2. 30ì¼ ì „ ê¸°ì¤€ì  ê³„ì‚°
        from app.utils.datetime_utils import days_ago_utc
        thirty_days_ago = days_ago_utc(30)

        # 3. í•´ë‹¹ í€˜ìŠ¤íŠ¸ ì¤‘ ê¸°ì¤€ì  ì´ì „ì˜ ê¸°ë¡ë§Œ ì‚­ì œ
        deleted_count = db.query(UserQuest).filter(
            UserQuest.quest_id.in_(repeatable_quest_ids),
            UserQuest.completed_at < thirty_days_ago.replace(tzinfo=None)
        ).delete(synchronize_session=False)
        
        db.commit()
        logger.info(f"âœ… Cleanup complete: Deleted {deleted_count} records older than 30 days.")
        return f"Successfully deleted {deleted_count} records."
        
    except Exception as e:
        logger.error(f"âŒ Cleanup Task Failed: {e}")
        db.rollback()
        return str(e)
    finally:
        db.close()

# =================================================================
# 6. [Daily Gift] ì„ ë¬¼ ìƒì„± ì›Œì»¤ (ê°œë³„ ìœ ì €ìš©)
# =================================================================
@celery_app.task(bind=True)
def task_generate_user_gift(self, user_id: int, force_update: bool = False):
    """
    [Async] íŠ¹ì • ìœ ì €ë¥¼ ìœ„í•œ ë°ì¼ë¦¬ ì„ ë¬¼ ìƒì„± (ê³µí†µ ë¡œì§ í˜¸ì¶œ)
    - force_update: Trueì¼ ê²½ìš° ê¸°ì¡´ ì„ ë¬¼ì„ ë®ì–´ì”€
    """
    try:
        run_gift_generation_sync(user_id, force_update=force_update)
    except Exception as e:
        logger.error(f"âŒ Worker Gift Task Failed: {e}")

@celery_app.task(bind=True)
def task_schedule_daily_gifts(self):
    """
    ë§¤ì¼ ì •í•´ì§„ ì‹œê°„(17:30 KST)ì— ëª¨ë“  í™œì„± ìœ ì €ì˜ ì„ ë¬¼ì„ *ìƒˆë¡œ ìƒì„±í•˜ì—¬ ë®ì–´ì”Œì›€*
    """
    db = SessionLocal()
    try:
        from app.utils.datetime_utils import now_kst
        target_date = now_kst().strftime("%Y-%m-%d")
        
        # 1. í™œì„± ìœ ì € ì¡°íšŒ
        users = db.query(User).filter(User.is_active == True).all()
        logger.info(f"â° Starting daily gift scheduling for {len(users)} users (Target: {target_date}, Force Update)...")
        
        count = 0
        for user in users:
            # [Change] ì¡°ê±´(exists) ì²´í¬ ì—†ì´ ë¬´ì¡°ê±´ ì¬ìƒì„±(force_update=True) ìš”ì²­
            # ì‚¬ìš©ìì˜ ìš”êµ¬: "ë§¤ í•œêµ­ì‹œê°„ ì˜¤í›„ 5ì‹œ30ë¶„ ë§ˆë‹¤ ìƒˆë¡œ ì„ ë¬¼ë“¤ì´ ìƒì„±ë˜ì–´ ë®ì–´ì”Œì›Œì§€ëŠ” ë¡œì§"
            task_generate_user_gift.delay(user.id, force_update=True)
            count += 1
                
        logger.info(f"âœ… Scheduled {count} gift generation tasks (Overwrite Mode).")
        
    except Exception as e:
        logger.error(f"âŒ Daily Gift Schedule Failed: {e}")
    finally:
        db.close()


# =================================================================
# 8. [í•µì‹¬] AI í†µí•© ìƒì„± ì›Œì»¤ (ì‹œê°í™” ë°ì´í„° ì „ë‹¬ ê°•í™”)
# =================================================================
@celery_app.task(bind=True)
def task_generate_draft(self, token: str, request_data: dict):
    """
    [Async] AI í†µí•© ì‘ì—… ì²˜ë¦¬ ì›Œì»¤
    """
    req_type = request_data.get('type') or request_data.get('template_type') or 'tech_blog'
    repo_target = request_data.get('repo_name') or request_data.get('source_repo')
    
    # [Debug Visual] ì œê±° ë° ê°„ì†Œí™”
    # logger.info("="*60) 
    # logger.info(f"ğŸ“¥ [Worker Recv] Request Type: {req_type}")
    # ... ê³¼ë„í•œ ë¡œê¹… ì œê±° ...

    try:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        async def run_dispatch():
            # -----------------------------------------------------
            # [Case 1] Docs Content Generation (ë¬¸ì„œ ë‚´ìš© ìƒì„±)
            # -----------------------------------------------------
            if req_type == 'docs_copilot':
                logger.info("ğŸ“„ [Docs Copilot] Initializing Service...")
                service = DocsGeneratorService(token=token)
                
                # [Fix] ìˆ˜ì •í•œ ì„œë¹„ìŠ¤ ë©”ì„œë“œ ì„œëª…ì— ë§ì¶° ëª¨ë“  ì¸ì ì „ë‹¬
                markdown_result = await service.generate_content(
                    repo_name=repo_target,
                    branch=request_data.get('branch', 'main'),
                    doc_path=request_data.get('doc_path', 'new_doc.md'),
                    reference_files=request_data.get('reference_files', []),
                    
                    # [Critical] ì„œë¹„ìŠ¤ ë‚´ë¶€ì˜ ë¡œê¹…ì´ ë™ì‘í•˜ë ¤ë©´ ì´ ê°’ë“¤ì´ ë“¤ì–´ê°€ì•¼ í•¨
                    user_prompt=request_data.get('user_prompt', ''),
                    doc_title=request_data.get('doc_title'),     # DTO í•„ë“œëª… í™•ì¸
                    doc_context=request_data.get('doc_context')  # DTO í•„ë“œëª… í™•ì¸
                )
                
                logger.info("âœ… [Docs Copilot] Content Generated Successfully.")
                return {
                    "task_type": "docs_copilot",
                    "markdown_template": markdown_result
                }

            # -----------------------------------------------------
            # [Case 2] Docs Source Recommendation (íŒŒì¼ ì¶”ì²œ)
            # -----------------------------------------------------
            elif req_type == 'docs_recommend':
                logger.info("ğŸ” [Docs Recommend] Initializing Service...")
                service = DocsGeneratorService(token=token)
                
                files = await service.recommend_related_files(
                    repo_name=repo_target,
                    branch=request_data.get('branch', 'main'),
                    doc_title=request_data.get('doc_title', ''),
                    doc_context=request_data.get('doc_context', '')
                )
                
                safe_files = files
                if isinstance(files, list) and len(files) > 0 and hasattr(files[0], 'model_dump'):
                    safe_files = [f.model_dump(mode='json') for f in files]

                return {
                    "task_type": "docs_recommend",
                    "recommendations": safe_files
                }

            # -----------------------------------------------------
            # [Case 3] Tech Blog Posting
            # -----------------------------------------------------
            else:
                service = AiPostingService(token)
                result = await service.generate_post(request_data)
                return { "task_type": "tech_blog", **result.model_dump(mode='json') }

        result_data = loop.run_until_complete(run_dispatch())
        return result_data

    except Exception as e:
        error_msg = f"âŒ [AI Task Failed] {str(e)}"
        logger.error(error_msg)
        logger.error(traceback.format_exc())
        raise e

# --- Celery Beat Schedule ---
celery_app.conf.beat_schedule = {
    "weekly-quest-cleanup": {
        "task": "app.worker.task_cleanup_old_quest_records",
        "schedule": crontab(hour=0, minute=0, day_of_week="monday"),
    },
    "daily-gift-generation": {
        "task": "app.worker.task_schedule_daily_gifts",
        "schedule": crontab(hour=15, minute=0), # UTC 15:00 -> KST 00:00 (Midnight)
    },
}